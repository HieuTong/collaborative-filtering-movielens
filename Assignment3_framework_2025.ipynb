{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35b4f48-7fb8-4957-84f7-6e5750f0c38d",
   "metadata": {},
   "source": [
    "# Install and load necesary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2b15118-de76-4a63-a3ec-a3f45616fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c496a5-df6d-4838-93e9-59c2ed4df088",
   "metadata": {},
   "source": [
    "## Load the dataset using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab3d257-297a-42e4-9ef0-6771fd30358a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "df = pd.read_csv('ml-100k/u.data', names=['user_id', 'item_id', 'rating', 'timestamp'], sep='\\t')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8443bc64-6256-4f39-a892-19fd6fd105a0",
   "metadata": {},
   "source": [
    "# Split dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639b70f3-da86-4492-ad1d-054842f1123d",
   "metadata": {},
   "source": [
    "## Randomly select one rating from each user as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52cfa457-e512-4218-9554-ff98c29edf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n",
      "Construct the rating matrix based on train_df:\n",
      "[[0. 3. 4. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 5. 0. ... 0. 0. 0.]]\n",
      "Construct the rating matrix based on test_df:\n",
      "[[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Testsize = 17678\n"
     ]
    }
   ],
   "source": [
    "# please do not change this cell\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print(str(n_users) + ' users')\n",
    "print(str(n_items) + ' items')\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state = 10)\n",
    "train_df, test_df\n",
    "\n",
    "# Training Dataset\n",
    "train_ds = np.zeros((n_users, n_items))\n",
    "item_popularity = np.zeros(n_items)\n",
    "for row in train_df.itertuples():\n",
    "    train_ds[row[1]-1, row[2]-1] = row[3]\n",
    "    item_popularity[row[2]-1] =  item_popularity[row[2]-1] + 1\n",
    "#train_ds = pd.DataFrame(train_ds)\n",
    "\n",
    "# Testing Dataset\n",
    "testsize = 0\n",
    "test_ds = np.zeros((n_users, n_items))\n",
    "for row in test_df.itertuples():\n",
    "    if item_popularity[row[2]-1] > 30:\n",
    "        test_ds[row[1]-1, row[2]-1] = row[3]\n",
    "        testsize = testsize + 1\n",
    "#test_ds = pd.DataFrame(test_ds)\n",
    "\n",
    "print(\"Construct the rating matrix based on train_df:\")\n",
    "print(train_ds)\n",
    "\n",
    "print(\"Construct the rating matrix based on test_df:\")\n",
    "print(test_ds)\n",
    "\n",
    "print(\"Testsize = \" + str(testsize))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2327db3f-c8c4-4d5d-a1d0-a7e762118a49",
   "metadata": {},
   "source": [
    "# MAE and RMSE Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac15b08-ee5a-4d8a-a5a9-fed6917b9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "# you can use this devaluate Utils here, and you can also implement your own MAE and RMSE calculation. \n",
    "\n",
    "EPSILON = 1e-9\n",
    "\n",
    "def evaluate(test_ds, predicted_ds):\n",
    "    '''\n",
    "    Function for evaluating on MAE and RMSE\n",
    "    '''\n",
    "    # MAE\n",
    "    mask_test_ds = test_ds > 0\n",
    "    MAE = np.sum(np.abs(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32))\n",
    "\n",
    "    # RMSE\n",
    "    RMSE = np.sqrt(np.sum(np.square(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32)))\n",
    "\n",
    "    return MAE, RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a51a1-19ab-4a11-b3d3-e046b0051e1a",
   "metadata": {},
   "source": [
    "# Your Solution for Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61330a1d-7092-4b12-86b0-2d7a60d6f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here for Method 1\n",
    "# You are required to implement the required solution 1 here. \n",
    "# Then, evaluate your implementation by predicting the ratings in the test set (test_ds).\n",
    "# Finally, save the corresponding MAE and RMSE of your implementation \n",
    "# into the following defined corresponding variable. \n",
    "\n",
    "# Method 1: User average rating\n",
    "\n",
    "# create binary matrix for ratings (1 is rated, 0 is not rated)\n",
    "ratings_mark = (train_ds > 0).astype(int)\n",
    "\n",
    "# calculate user average ratings\n",
    "user_rated_counts = ratings_mark.sum(axis=1)\n",
    "user_ratings_sum = train_ds.sum(axis=1)\n",
    "user_avg_ratings = user_ratings_sum / (user_rated_counts + EPSILON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7657d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the test set\n",
    "predicted_ds_method1 = np.zeros_like(test_ds)\n",
    "test_mask = test_ds > 0\n",
    "for user_idx in range(n_users):\n",
    "    user_test_items = test_mask[user_idx]\n",
    "    predicted_ds_method1[user_idx, user_test_items] = user_avg_ratings[user_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a631a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the MAE and RMSE of method 1\n",
    "MAE_solution1, RMSE_solution1 = evaluate(test_ds, predicted_ds_method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cec8efe6-8214-46de-acce-6b5bf24c245a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== The MAE and RMSE of Your Implementation =====================\n",
      "MAE: 0.8258905090160901, RMSE: 1.0311430705959619\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "print(\"===================== The MAE and RMSE of Your Implementation =====================\")\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE_solution1, RMSE_solution1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1b9cc5-6fa4-48c6-8a44-edd6d9a8729d",
   "metadata": {},
   "source": [
    "# Your Solution for Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5291b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: item average rating\n",
    "# create binary matrix for ratings (1 is rated, 0 is not rated)\n",
    "ratings_mark = (train_ds > 0).astype(int)\n",
    "\n",
    "# calculate user average ratings\n",
    "item_rated_counts = ratings_mark.sum(axis=0)\n",
    "item_rating_sums = train_ds.sum(axis=0)\n",
    "item_avg_ratings = item_rating_sums / (item_rated_counts + EPSILON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1427b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for test items\n",
    "predicted_ds_method2 = np.zeros_like(test_ds)\n",
    "test_mask = test_ds > 0\n",
    "\n",
    "# Still need a loop for applying predictions\n",
    "for item_idx in range(n_items):\n",
    "    item_test_users = test_mask[:, item_idx]\n",
    "    predicted_ds_method2[item_test_users, item_idx] = item_avg_ratings[item_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be5ec1b4-5825-4c05-a950-04a4ae7300bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_solution2, RMSE_solution2 = evaluate(test_ds, predicted_ds_method2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95dc2f56-5802-420c-aa87-3ed5d89ea030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== The MAE and RMSE of Your Implementation =====================\n",
      "MAE: 0.7961203951019012, RMSE: 1.001314210158761\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "print(\"===================== The MAE and RMSE of Your Implementation =====================\")\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE_solution2, RMSE_solution2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9281c64-c5e2-451b-a69a-2d9965271093",
   "metadata": {},
   "source": [
    "# Your Solution for Method 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0854e8",
   "metadata": {},
   "source": [
    "#### Method 3: User knn based collaborative filtering \n",
    "- Compute the similarity by pearson similarity and cosine similarity, we could add another method to optimize such as Eucludian, in this case compare two correlations above.\n",
    "- Then choose the better method, we tune the parameters. \n",
    "- By doing that, we find weight, then choose the k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e1209c4-3c44-4e88-814c-0c8afaac0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here for Method 3\n",
    "# func to compute Pearson similarity\n",
    "def compute_pearson_similarity(train_data, sig_weight=25):\n",
    "    n_users = train_data.shape[0]\n",
    "    similarity_matrix = np.zeros((n_users, n_users))\n",
    "\n",
    "    # pre calculate user ratings mean\n",
    "    user_means = np.zeros(n_users)\n",
    "    for i in range(n_users):\n",
    "        mask = train_data[i] > 0\n",
    "        if np.sum(mask) > 0:  \n",
    "            user_means[i] = np.sum(train_data[i][mask]) / np.sum(mask)\n",
    "\n",
    "    # compute similarity\n",
    "\n",
    "    for i in range(n_users):\n",
    "        # self similarity always equals to 1\n",
    "        similarity_matrix[i, i] = 1.0\n",
    "\n",
    "        for j in range(i + 1, n_users):\n",
    "            # find co-rated items \n",
    "            mask_i = train_data[i] > 0\n",
    "            mask_j = train_data[j] > 0\n",
    "            corrated_idx = np.logical_and(mask_i, mask_j)\n",
    "            corrated_items = np.where(corrated_idx)[0]\n",
    "\n",
    "            if len(corrated_items) == 0:\n",
    "                continue\n",
    "\n",
    "            # center the ratings vectors\n",
    "            user_i_centered = train_data[i][corrated_items] - user_means[i]\n",
    "            user_j_centered = train_data[j][corrated_items] - user_means[j]\n",
    "\n",
    "            # calculate the Pearson correlation coefficient\n",
    "            r_ui_sub_r_i_sq = np.square(user_i_centered)\n",
    "            r_uj_sub_r_j_sq = np.square(user_j_centered)\n",
    "\n",
    "            r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "            r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "            sim = np.sum(user_i_centered * user_j_centered) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "            weight_sim = (min(len(corrated_items), sig_weight) / sig_weight) * sim\n",
    "            # Store in both positions (symmetric matrix)\n",
    "            similarity_matrix[i, j] = weight_sim\n",
    "            similarity_matrix[j, i] = weight_sim\n",
    "    \n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c306c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to compute cosine similarity\n",
    "def compute_consine_similarity(train_data, sig_weight=25):\n",
    "    n_users = train_data.shape[0]\n",
    "    similarity_matrix = np.zeros((n_users, n_users))\n",
    "\n",
    "    # compute similarity\n",
    "    for i in range(n_users):\n",
    "        # self similarity always equals to 1\n",
    "        similarity_matrix[i, i] = 1.0\n",
    "\n",
    "        for j in range(i + 1, n_users):\n",
    "            # find co-rated items \n",
    "            mask_i = train_data[i] > 0\n",
    "            mask_j = train_data[j] > 0\n",
    "            corrated_idx = np.logical_and(mask_i, mask_j)\n",
    "            num_corated = np.sum(corrated_idx)\n",
    "\n",
    "            # If no co-rated items, skip\n",
    "            if num_corated == 0:\n",
    "                continue\n",
    "\n",
    "            # Extract ratings for co-rated items\n",
    "            user_i_corated = train_data[i][corrated_idx]\n",
    "            user_j_corated = train_data[j][corrated_idx]\n",
    "\n",
    "            # Calculate cosine similarity\n",
    "            dot_product = np.sum(user_i_corated * user_j_corated)\n",
    "            norm_i = np.sqrt(np.sum(np.square(user_i_corated)))\n",
    "            norm_j = np.sqrt(np.sum(np.square(user_j_corated)))\n",
    "\n",
    "            sim = dot_product / (norm_i * norm_j + EPSILON)\n",
    "            weighted_sim = (min(num_corated, sig_weight) / sig_weight) * sim\n",
    "            \n",
    "            # Store in both positions (symmetric matrix)\n",
    "            similarity_matrix[i, j] = weighted_sim\n",
    "            similarity_matrix[j, i] = weighted_sim\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb0fe3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to predict ratings using user-based collaborative filtering \n",
    "def predict_ratings(train_data, similarity_matrix, test_data, k=30):\n",
    "    n_users, n_items = train_data.shape \n",
    "    predicted_ratings = np.zeros_like(test_data)\n",
    "    test_mask = test_data > 0\n",
    "\n",
    "    # pre-calculate user means to fill value for ratings if no neighbors rate the item\n",
    "    user_means = np.zeros(n_users)\n",
    "    for i in range(n_users):\n",
    "        mask = train_data[i] > 0\n",
    "        if np.sum(mask) > 0:\n",
    "            user_means[i] = np.sum(train_data[i][mask]) / np.sum(mask)\n",
    "\n",
    "    # Make the predict for all test items\n",
    "    for i in range(n_users):\n",
    "        user_test_items = np.where(test_mask[i])[0]\n",
    "        if len(user_test_items) == 0:\n",
    "            continue\n",
    "\n",
    "        # Find the k most similar users (exluding self)\n",
    "        similar_users = np.argsort(similarity_matrix[i])[::-1]\n",
    "        similar_users = similar_users[similar_users != i][:k]\n",
    "\n",
    "        for item_idx in user_test_items:\n",
    "            # find the neighbors who rate that item\n",
    "            mark_rated_item = train_data[similar_users, item_idx] > 0\n",
    "            neighbors = similar_users[mark_rated_item]\n",
    "\n",
    "            if len(neighbors) == 0:\n",
    "                predicted_ratings[i, item_idx] = user_means[i]  # use user mean if no neighbors rated the item\n",
    "                continue\n",
    "        \n",
    "            # Get similarities and ratings of neighbors \n",
    "            neighbor_similarities = similarity_matrix[i, neighbors]\n",
    "            neighbor_ratings = train_data[neighbors, item_idx]\n",
    "\n",
    "            # Calculate the neighbor means and weight difference\n",
    "            neighbor_means = user_means[neighbors]\n",
    "            weighted_diff = neighbor_ratings - neighbor_means\n",
    "\n",
    "            # Calculate the predicted rating\n",
    "            sim_sum = np.sum(neighbor_similarities) \n",
    "            prediction = user_means[i] + np.sum(neighbor_similarities * weighted_diff) / (sim_sum + EPSILON)\n",
    "            predicted_ratings[i, item_idx] = np.clip(prediction, 1, 5)\n",
    "\n",
    "    return predicted_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcbe3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate similarity matrix using Pearson correlation and Cosine similarity\n",
    "pearson_sim = compute_pearson_similarity(train_ds, sig_weight=25)\n",
    "cosine_sim = compute_consine_similarity(train_ds, sig_weight=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f54bc136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different parameters k and weight\n",
    "# Different k values\n",
    "\n",
    "k_values = [20, 30, 50, 100]\n",
    "\n",
    "# save in this result\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff0c6e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson k=20: MAE=0.7775, RMSE=1.0047\n",
      "Cosine k=20: MAE=0.7898, RMSE=1.0152\n",
      "Pearson k=30: MAE=0.7574, RMSE=0.9775\n",
      "Cosine k=30: MAE=0.7734, RMSE=0.9922\n",
      "Pearson k=50: MAE=0.7393, RMSE=0.9542\n",
      "Cosine k=50: MAE=0.7555, RMSE=0.9683\n",
      "Pearson k=100: MAE=0.7250, RMSE=0.9345\n",
      "Cosine k=100: MAE=0.7382, RMSE=0.9462\n"
     ]
    }
   ],
   "source": [
    "# test different k values for both similarity methods\n",
    "for k in k_values:\n",
    "    # Test with Pearson similarity\n",
    "    predicted_ratings_pearson = predict_ratings(train_ds, pearson_sim, test_ds, k=k)\n",
    "    mae_p, rmse_p = evaluate(test_ds, predicted_ratings_pearson)\n",
    "    results.append((\"Standard\", \"Pearson\", 25, k, mae_p, rmse_p))\n",
    "    print(f\"Pearson k={k}: MAE={mae_p:.4f}, RMSE={rmse_p:.4f}\")\n",
    "    \n",
    "    # Test with Cosine similarity\n",
    "    predicted_ratings_cosine = predict_ratings(train_ds, cosine_sim, test_ds, k=k)\n",
    "    mae_c, rmse_c = evaluate(test_ds, predicted_ratings_cosine)\n",
    "    results.append((\"Standard\", \"Cosine\", 25, k, mae_c, rmse_c))\n",
    "    print(f\"Cosine k={k}: MAE={mae_c:.4f}, RMSE={rmse_c:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad0e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_solution3 = 0 # 0 is an intial value, you need to update this with the actual perofrmancae of your implementation.\n",
    "RMSE_solution3 = 0 # 0 is an intial value, you need to update this with the actual perofrmance of your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f517513-1805-4a3e-ad30-09fdb19bdeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== The MAE and RMSE of Your Implementation =====================\n",
      "MAE: 0, RMSE: 0\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "print(\"===================== The MAE and RMSE of Your Implementation =====================\")\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE_solution3, RMSE_solution3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dfa165-49ce-4bb2-96a8-a86ab58705d4",
   "metadata": {},
   "source": [
    "# Your Solution for Method 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "413fb7bf-0efa-4fe0-8f5c-874db8f531fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here for Method 4\n",
    "# You are required to implement the required solution 1 here. \n",
    "# Then, evaluate your implementation by predicting the ratings in the test set (test_ds).\n",
    "# Finally, save the corresponding MAE and RMSE of your implementation \n",
    "# into the following defined corresponding variable. \n",
    "\n",
    "MAE_solution4 = 0 # 0 is an intial value, you need to update this with the actual perofrmance of your implementation.\n",
    "RMSE_solution4 = 0 # 0 is an intial value, you need to update this with the actual perofrmance of your implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47c9516a-2c5b-4783-a461-c35514975fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== The MAE and RMSE of Your Implementation =====================\n",
      "MAE: 0, RMSE: 0\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "print(\"===================== The MAE and RMSE of Your Implementation =====================\")\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE_solution4, RMSE_solution4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82ecd8b-5248-4154-be35-139e1eb9ce1c",
   "metadata": {},
   "source": [
    "# Your Solution for Method 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b13f73f-3004-47e1-976e-6895c8e2d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here for Method 5\n",
    "# You are required to implement the required solution 1 here. \n",
    "# Then, evaluate your implementation by predicting the ratings in the test set (test_ds).\n",
    "# Finally, save the corresponding MAE and RMSE of your implementation \n",
    "# into the following defined corresponding variable. \n",
    "\n",
    "MAE_solution5 = 0 # 0 is an intial value, you need to update this with the actual perofrmance of your implementation.\n",
    "RMSE_solution5 = 0 # 0 is an intial value, you need to update this with the actual perofrmance of your implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "083bdb74-5627-417a-91ea-388f9353fc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== The MAE and RMSE of Your Implementation =====================\n",
      "MAE: 0, RMSE: 0\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "print(\"===================== The MAE and RMSE of Your Implementation =====================\")\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE_solution5, RMSE_solution5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d1d2a-0a08-46da-a809-c82af42dd36c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
